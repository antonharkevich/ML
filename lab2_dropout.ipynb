{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebdc89e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AntonHarkevich\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#all necessary imports\n",
    "from PIL import Image\n",
    "import io\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import imagehash\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import splitfolders\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf1e182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "validation data\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n"
     ]
    }
   ],
   "source": [
    "#set max train images amount, validation images amount, test images amount\n",
    "train_size = 200000\n",
    "validation_size = 10000\n",
    "test_size = 19000\n",
    "\n",
    "#set of all letters in dataset\n",
    "letter_set = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "\n",
    "#dict for convert letters to numbers\n",
    "letter_dict = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'G': 6,\n",
    "    'H': 7,\n",
    "    'I': 8,\n",
    "    'J': 9\n",
    "}\n",
    "\n",
    "#scores dictionary for plot \n",
    "scores_test = {}\n",
    "scores_val  = {}\n",
    "\n",
    "\n",
    "\n",
    "#test data\n",
    "x_test = []\n",
    "\n",
    "#test labels\n",
    "y_test = []\n",
    "\n",
    "print('test data')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for letter in letter_set:\n",
    "    folder = Path(f\"./for_train_all_{train_size}_nw/test/{letter}_new\")\n",
    "    if folder.is_dir():\n",
    "        for file in folder.iterdir():\n",
    "            #use the asarray function to convert an image to array of pixel values based on the color of the pixel  \n",
    "            x_test.append(asarray(Image.open(file)))\n",
    "\n",
    "            #add letter label number\n",
    "            y_test.append(letter_dict[letter])\n",
    "            \n",
    "            i += 1\n",
    "                \n",
    "            if(i % 1000 == 0):\n",
    "                print(i)\n",
    "            \n",
    "            \n",
    "#validation data\n",
    "x_valid = []\n",
    "\n",
    "#validation labels\n",
    "y_valid = []\n",
    "\n",
    "print('validation data')\n",
    "\n",
    "for letter in letter_set:\n",
    "    folder = Path(f\"./for_train_all_{train_size}_nw/val/{letter}_new\")\n",
    "    if folder.is_dir():\n",
    "        for file in folder.iterdir():\n",
    "            #use the asarray function to convert an image to array of pixel values based on the color of the pixel  \n",
    "            x_valid.append(asarray(Image.open(file)))\n",
    "\n",
    "            #add letter label number\n",
    "            y_valid.append(letter_dict[letter])\n",
    "            \n",
    "            i += 1\n",
    "                \n",
    "            if(i % 1000 == 0):\n",
    "                print(i)\n",
    "                \n",
    "#convert test image data and labels to numpy arrays and normalize data             \n",
    "x_test = np.array(x_test) / 255.0\n",
    "y_test = np.array(y_test)     \n",
    "\n",
    "#convert validation image data and labels to numpy arrays and normalize data \n",
    "x_valid = np.array(x_valid) / 255.0\n",
    "y_valid = np.array(y_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "560fed95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "WARNING:tensorflow:From C:\\Users\\AntonHarkevich\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:From C:\\Users\\AntonHarkevich\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\AntonHarkevich\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 2.4420 - accuracy: 0.0600\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4112 - accuracy: 0.0800\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3280 - accuracy: 0.1200\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.3398 - accuracy: 0.1200\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.3761 - accuracy: 0.1000\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.2604 - accuracy: 0.1200\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3199 - accuracy: 0.1200\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3904 - accuracy: 0.1400\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1886 - accuracy: 0.2600\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3091 - accuracy: 0.1000\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1690 - accuracy: 0.3200\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2070 - accuracy: 0.2200\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1922 - accuracy: 0.2400\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2153 - accuracy: 0.2200\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1944 - accuracy: 0.2600\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1357 - accuracy: 0.2400\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1050 - accuracy: 0.3400\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1443 - accuracy: 0.3000\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2028 - accuracy: 0.2200\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0990 - accuracy: 0.2800\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1142 - accuracy: 0.2400\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1150 - accuracy: 0.2600\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1586 - accuracy: 0.1800\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1329 - accuracy: 0.3000\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0658 - accuracy: 0.3200\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0071 - accuracy: 0.3000\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0818 - accuracy: 0.3400\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0382 - accuracy: 0.3800\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0052 - accuracy: 0.3800\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9933 - accuracy: 0.4000\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0105 - accuracy: 0.4000\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0619 - accuracy: 0.3400\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0201 - accuracy: 0.4000\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9294 - accuracy: 0.4000\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9573 - accuracy: 0.4600\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8798 - accuracy: 0.4600\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8335 - accuracy: 0.5200\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8843 - accuracy: 0.4400\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8903 - accuracy: 0.4400\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9679 - accuracy: 0.4000\n",
      "end fit\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 2.1398 - accuracy: 0.2997\n",
      "Test score for measure 50 loss: 2.1398372650146484\n",
      "Test score for measure 50 accuracy: 0.2997368276119232\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 2.1457 - accuracy: 0.2940\n",
      "Validation score for measure 50 loss: 2.145657777786255\n",
      "Validation score for measure 50 accuracy: 0.2939999997615814\n",
      "start fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AntonHarkevich\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.5922 - accuracy: 0.1200\n",
      "Epoch 2/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.4254 - accuracy: 0.1600\n",
      "Epoch 3/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.3801 - accuracy: 0.1900\n",
      "Epoch 4/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2491 - accuracy: 0.1800\n",
      "Epoch 5/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2962 - accuracy: 0.1900\n",
      "Epoch 6/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2857 - accuracy: 0.1600\n",
      "Epoch 7/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1922 - accuracy: 0.2300\n",
      "Epoch 8/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1878 - accuracy: 0.2600\n",
      "Epoch 9/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.1751 - accuracy: 0.2500\n",
      "Epoch 10/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0960 - accuracy: 0.2500\n",
      "Epoch 11/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0661 - accuracy: 0.3300\n",
      "Epoch 12/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0990 - accuracy: 0.3200\n",
      "Epoch 13/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0933 - accuracy: 0.3000\n",
      "Epoch 14/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0410 - accuracy: 0.2800\n",
      "Epoch 15/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0490 - accuracy: 0.2800\n",
      "Epoch 16/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0270 - accuracy: 0.2900\n",
      "Epoch 17/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0044 - accuracy: 0.3000\n",
      "Epoch 18/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9830 - accuracy: 0.3900\n",
      "Epoch 19/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9610 - accuracy: 0.3800\n",
      "Epoch 20/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8550 - accuracy: 0.4100\n",
      "Epoch 21/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8842 - accuracy: 0.4200\n",
      "Epoch 22/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8132 - accuracy: 0.4600\n",
      "Epoch 23/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7945 - accuracy: 0.4500\n",
      "Epoch 24/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.7387 - accuracy: 0.4600\n",
      "Epoch 25/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7308 - accuracy: 0.4700\n",
      "Epoch 26/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7288 - accuracy: 0.5000\n",
      "Epoch 27/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8159 - accuracy: 0.4300\n",
      "Epoch 28/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.7258 - accuracy: 0.4700\n",
      "Epoch 29/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7915 - accuracy: 0.4500\n",
      "Epoch 30/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.5826 - accuracy: 0.6100\n",
      "Epoch 31/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.6309 - accuracy: 0.5200\n",
      "Epoch 32/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.6390 - accuracy: 0.5200\n",
      "Epoch 33/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.6251 - accuracy: 0.5500\n",
      "Epoch 34/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5427 - accuracy: 0.5200\n",
      "Epoch 35/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5525 - accuracy: 0.5700\n",
      "Epoch 36/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.5023 - accuracy: 0.5700\n",
      "Epoch 37/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.4470 - accuracy: 0.6600\n",
      "Epoch 38/40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4699 - accuracy: 0.5900\n",
      "Epoch 39/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3945 - accuracy: 0.6400\n",
      "Epoch 40/40\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.4025 - accuracy: 0.6200\n",
      "end fit\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 1.7138 - accuracy: 0.5071\n",
      "Test score for measure 100 loss: 1.7138488292694092\n",
      "Test score for measure 100 accuracy: 0.50710529088974\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.7272 - accuracy: 0.5067\n",
      "Validation score for measure 100 loss: 1.7271584272384644\n",
      "Validation score for measure 100 accuracy: 0.5066999793052673\n",
      "1000\n",
      "start fit\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 2.3856 - accuracy: 0.1320\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.2127 - accuracy: 0.2190\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.1087 - accuracy: 0.2930\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.9946 - accuracy: 0.3590\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.8510 - accuracy: 0.4360\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.7562 - accuracy: 0.4680\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.6567 - accuracy: 0.4970\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.5356 - accuracy: 0.5410\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.4725 - accuracy: 0.5480\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.4223 - accuracy: 0.5830\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3527 - accuracy: 0.6120\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3038 - accuracy: 0.6320\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2484 - accuracy: 0.6520\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2159 - accuracy: 0.6520\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1938 - accuracy: 0.6810\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1547 - accuracy: 0.6770\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0910 - accuracy: 0.6820\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1027 - accuracy: 0.6590\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0334 - accuracy: 0.7020\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0374 - accuracy: 0.7140\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9709 - accuracy: 0.7310\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0087 - accuracy: 0.7180\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9471 - accuracy: 0.7310\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9465 - accuracy: 0.7450\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9190 - accuracy: 0.7380\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9028 - accuracy: 0.7600\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9016 - accuracy: 0.7470\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8870 - accuracy: 0.7420\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8511 - accuracy: 0.7540\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8407 - accuracy: 0.7600\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8097 - accuracy: 0.7840\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7774 - accuracy: 0.7840\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7794 - accuracy: 0.7770\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7802 - accuracy: 0.7980\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.7920\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7304 - accuracy: 0.8020\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7441 - accuracy: 0.7890\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.8100\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.8260\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.7990\n",
      "end fit\n",
      "594/594 [==============================] - 1s 993us/step - loss: 0.8899 - accuracy: 0.7473\n",
      "Test score for measure 1000 loss: 0.8898618221282959\n",
      "Test score for measure 1000 accuracy: 0.7473157644271851\n",
      "313/313 [==============================] - 0s 984us/step - loss: 0.9174 - accuracy: 0.7434\n",
      "Validation score for measure 1000 loss: 0.9174157977104187\n",
      "Validation score for measure 1000 accuracy: 0.743399977684021\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "start fit\n",
      "Epoch 1/40\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 1.2318 - accuracy: 0.6310\n",
      "Epoch 2/40\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8276 - accuracy: 0.7672\n",
      "Epoch 3/40\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7616 - accuracy: 0.7868\n",
      "Epoch 4/40\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7242 - accuracy: 0.7983\n",
      "Epoch 5/40\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6984 - accuracy: 0.8066\n",
      "Epoch 6/40\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6767 - accuracy: 0.8110\n",
      "Epoch 7/40\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6610 - accuracy: 0.8167\n",
      "Epoch 8/40\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6404 - accuracy: 0.8203\n",
      "Epoch 9/40\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6294 - accuracy: 0.8233\n",
      "Epoch 10/40\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6139 - accuracy: 0.8290\n",
      "Epoch 11/40\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6027 - accuracy: 0.8319\n",
      "Epoch 12/40\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5918 - accuracy: 0.8346\n",
      "Epoch 13/40\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5819 - accuracy: 0.8364\n",
      "Epoch 14/40\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5725 - accuracy: 0.8391\n",
      "Epoch 15/40\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5606 - accuracy: 0.8432\n",
      "Epoch 16/40\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5523 - accuracy: 0.8455\n",
      "Epoch 17/40\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.5434 - accuracy: 0.8482\n",
      "Epoch 18/40\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5404 - accuracy: 0.8475\n",
      "Epoch 19/40\n",
      "1563/1563 [==============================] - 16s 11ms/step - loss: 0.5339 - accuracy: 0.8517\n",
      "Epoch 20/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.5235 - accuracy: 0.8536\n",
      "Epoch 21/40\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.5155 - accuracy: 0.8568\n",
      "Epoch 22/40\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.5106 - accuracy: 0.8561\n",
      "Epoch 23/40\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.5042 - accuracy: 0.8590\n",
      "Epoch 24/40\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5018 - accuracy: 0.8582\n",
      "Epoch 25/40\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.4929 - accuracy: 0.8622\n",
      "Epoch 26/40\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4866 - accuracy: 0.8637\n",
      "Epoch 27/40\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.4830 - accuracy: 0.8656\n",
      "Epoch 28/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4803 - accuracy: 0.8656\n",
      "Epoch 29/40\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.4768 - accuracy: 0.8680\n",
      "Epoch 30/40\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.4705 - accuracy: 0.8697\n",
      "Epoch 31/40\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.4632 - accuracy: 0.8703\n",
      "Epoch 32/40\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.4606 - accuracy: 0.8710\n",
      "Epoch 33/40\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.4572 - accuracy: 0.8733\n",
      "Epoch 34/40\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4541 - accuracy: 0.8733\n",
      "Epoch 35/40\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.4508 - accuracy: 0.8748\n",
      "Epoch 36/40\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.4419 - accuracy: 0.8788\n",
      "Epoch 37/40\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.4405 - accuracy: 0.8777\n",
      "Epoch 38/40\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.4340 - accuracy: 0.8800\n",
      "Epoch 39/40\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4321 - accuracy: 0.8793\n",
      "Epoch 40/40\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4273 - accuracy: 0.8810\n",
      "end fit\n",
      "594/594 [==============================] - 3s 3ms/step - loss: 0.5383 - accuracy: 0.8545\n",
      "Test score for measure 50000 loss: 0.5382611155509949\n",
      "Test score for measure 50000 accuracy: 0.8545263409614563\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5600 - accuracy: 0.8483\n",
      "Validation score for measure 50000 loss: 0.5600433349609375\n",
      "Validation score for measure 50000 accuracy: 0.8482999801635742\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "start fit\n",
      "Epoch 1/40\n",
      "6250/6250 [==============================] - 19s 3ms/step - loss: 0.8987 - accuracy: 0.7410\n",
      "Epoch 2/40\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 0.6954 - accuracy: 0.8071\n",
      "Epoch 3/40\n",
      "6250/6250 [==============================] - 17s 3ms/step - loss: 0.6474 - accuracy: 0.8196\n",
      "Epoch 4/40\n",
      "6250/6250 [==============================] - 17s 3ms/step - loss: 0.6162 - accuracy: 0.8281\n",
      "Epoch 5/40\n",
      "6250/6250 [==============================] - 18s 3ms/step - loss: 0.5919 - accuracy: 0.8350\n",
      "Epoch 6/40\n",
      "6250/6250 [==============================] - 20s 3ms/step - loss: 0.5733 - accuracy: 0.8402\n",
      "Epoch 7/40\n",
      "6250/6250 [==============================] - 20s 3ms/step - loss: 0.5591 - accuracy: 0.8444\n",
      "Epoch 8/40\n",
      "6250/6250 [==============================] - 20s 3ms/step - loss: 0.5443 - accuracy: 0.8483\n",
      "Epoch 9/40\n",
      "6250/6250 [==============================] - 26s 4ms/step - loss: 0.5354 - accuracy: 0.8505\n",
      "Epoch 10/40\n",
      "6250/6250 [==============================] - 19s 3ms/step - loss: 0.5254 - accuracy: 0.8533\n",
      "Epoch 11/40\n",
      "6250/6250 [==============================] - 17s 3ms/step - loss: 0.5169 - accuracy: 0.8557\n",
      "Epoch 12/40\n",
      "6250/6250 [==============================] - 18s 3ms/step - loss: 0.5115 - accuracy: 0.8572\n",
      "Epoch 13/40\n",
      "6250/6250 [==============================] - 19s 3ms/step - loss: 0.5047 - accuracy: 0.8585\n",
      "Epoch 14/40\n",
      "6250/6250 [==============================] - 18s 3ms/step - loss: 0.4959 - accuracy: 0.8613\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 18s 3ms/step - loss: 0.4909 - accuracy: 0.8630\n",
      "Epoch 16/40\n",
      "6250/6250 [==============================] - 17s 3ms/step - loss: 0.4845 - accuracy: 0.8646\n",
      "Epoch 17/40\n",
      "6250/6250 [==============================] - 14s 2ms/step - loss: 0.4817 - accuracy: 0.8659\n",
      "Epoch 18/40\n",
      "6250/6250 [==============================] - 16s 2ms/step - loss: 0.4759 - accuracy: 0.8672\n",
      "Epoch 19/40\n",
      "6250/6250 [==============================] - 17s 3ms/step - loss: 0.4724 - accuracy: 0.8687\n",
      "Epoch 20/40\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 0.4672 - accuracy: 0.8697\n",
      "Epoch 21/40\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 0.4653 - accuracy: 0.8699\n",
      "Epoch 22/40\n",
      "6250/6250 [==============================] - 17s 3ms/step - loss: 0.4624 - accuracy: 0.8714\n",
      "Epoch 23/40\n",
      "6250/6250 [==============================] - 18s 3ms/step - loss: 0.4586 - accuracy: 0.8722\n",
      "Epoch 24/40\n",
      "6250/6250 [==============================] - 16s 2ms/step - loss: 0.4549 - accuracy: 0.8733\n",
      "Epoch 25/40\n",
      "6250/6250 [==============================] - 13s 2ms/step - loss: 0.4521 - accuracy: 0.8737\n",
      "Epoch 26/40\n",
      "6250/6250 [==============================] - 20s 3ms/step - loss: 0.4491 - accuracy: 0.8751\n",
      "Epoch 27/40\n",
      "6250/6250 [==============================] - 19s 3ms/step - loss: 0.4462 - accuracy: 0.8753\n",
      "Epoch 28/40\n",
      "6250/6250 [==============================] - 16s 2ms/step - loss: 0.4452 - accuracy: 0.8762\n",
      "Epoch 29/40\n",
      "6250/6250 [==============================] - 15s 2ms/step - loss: 0.4412 - accuracy: 0.8768\n",
      "Epoch 30/40\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 0.4392 - accuracy: 0.8776\n",
      "Epoch 31/40\n",
      "6250/6250 [==============================] - 15s 2ms/step - loss: 0.4373 - accuracy: 0.8783\n",
      "Epoch 32/40\n",
      "6250/6250 [==============================] - 15s 2ms/step - loss: 0.4356 - accuracy: 0.8788\n",
      "Epoch 33/40\n",
      "6250/6250 [==============================] - 15s 2ms/step - loss: 0.4324 - accuracy: 0.8803\n",
      "Epoch 34/40\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 0.4313 - accuracy: 0.8804\n",
      "Epoch 35/40\n",
      "6250/6250 [==============================] - 15s 2ms/step - loss: 0.4285 - accuracy: 0.8808\n",
      "Epoch 36/40\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 0.4294 - accuracy: 0.8811\n",
      "Epoch 37/40\n",
      "6250/6250 [==============================] - 15s 2ms/step - loss: 0.4246 - accuracy: 0.8819\n",
      "Epoch 38/40\n",
      "6250/6250 [==============================] - 16s 2ms/step - loss: 0.4250 - accuracy: 0.8824\n",
      "Epoch 39/40\n",
      "6250/6250 [==============================] - 16s 2ms/step - loss: 0.4225 - accuracy: 0.8827\n",
      "Epoch 40/40\n",
      "6250/6250 [==============================] - 15s 2ms/step - loss: 0.4211 - accuracy: 0.8833\n",
      "end fit\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 0.4257 - accuracy: 0.8825\n",
      "Test score for measure 200000 loss: 0.4256609380245209\n",
      "Test score for measure 200000 accuracy: 0.8824737071990967\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.8745\n",
      "Validation score for measure 200000 loss: 0.4469245970249176\n",
      "Validation score for measure 200000 accuracy: 0.8744999766349792\n"
     ]
    }
   ],
   "source": [
    "#each measure for plot \n",
    "for measure in ([50,100,1000,50000,200000]):  \n",
    "\n",
    "    \n",
    "    #train data\n",
    "    x_train = [0] * measure\n",
    "    #train labels\n",
    "    y_train = []\n",
    "    \n",
    "\n",
    "    i = 0\n",
    "        \n",
    "    for letter in letter_set:\n",
    "        folder = Path(f\"./for_train_all_{train_size}_nw/train/{letter}_new\")\n",
    "\n",
    "        if folder.is_dir():\n",
    "            for file in folder.iterdir():\n",
    "                #use the asarray function to convert an image to array of pixel values based on the color of the pixel  \n",
    "                x_train[i] = asarray(Image.open(file))\n",
    "                \n",
    "                #add letter label number\n",
    "                y_train.append(letter_dict[letter])\n",
    "                \n",
    "                i += 1\n",
    "                \n",
    "                if(i % 1000 == 0):\n",
    "                    print(i)\n",
    "                \n",
    "                if(i % (measure//10) == 0):\n",
    "                    break\n",
    "                    \n",
    "    #convert train image data and labels to numpy arrays and normalize data                 \n",
    "    x_train = np.array(x_train) / 255.0\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    print('start fit')\n",
    "    #prediction model\n",
    "    #Flatten layer to reshape image dimensions to a single dimension\n",
    "    #Dense layer of 128 neurons, 128 neurons and 64 neurons\n",
    "    #Dense layer with 10 neurons as number of letters\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(128, kernel_regularizer=tf.keras.regularizers.l2(0.0001), activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(128, kernel_regularizer=tf.keras.regularizers.l2(0.0001), activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.0001), activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    \n",
    "    #compile model with SGD optimizer, sparse_categorical_crossentropy loss and accuracy metric\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    #fit model with 40 epochs\n",
    "    model.fit(x_train, y_train, epochs=40)\n",
    "    \n",
    "    print('end fit')\n",
    "    \n",
    "    #calc test loss and accuracy\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test score for measure {measure} loss: {test_loss}\")\n",
    "    print(f\"Test score for measure {measure} accuracy: {test_acc}\")\n",
    "    \n",
    "    \n",
    "    scores_test[measure] = test_acc\n",
    "                    \n",
    "    #calc validation loss and accuracy\n",
    "    valid_loss, valid_acc = model.evaluate(x_valid, y_valid)\n",
    "    \n",
    "    print(f\"Validation score for measure {measure} loss: {valid_loss}\")\n",
    "    print(f\"Validation score for measure {measure} accuracy: {valid_acc}\")\n",
    "    \n",
    "    scores_val[measure] = valid_acc\n",
    "    \n",
    "    model.save(f\"lab_2_2_{measure}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d64e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{50: 0.2997368276119232, 100: 0.50710529088974, 1000: 0.7473157644271851, 50000: 0.8545263409614563, 200000: 0.8824737071990967}\n",
      "{50: 0.2939999997615814, 100: 0.5066999793052673, 1000: 0.743399977684021, 50000: 0.8482999801635742, 200000: 0.8744999766349792}\n"
     ]
    }
   ],
   "source": [
    "print(scores_test)\n",
    "print(scores_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea69e4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lists = sorted(scores_test.items()) # sorted by key, return a list of tuples\n",
    "\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f159a276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
